{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import pickle\n",
    "#from numba import cuda\n",
    "from scipy import spatial, sparse\n",
    "import random as rd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/fires_merged_weather.csv', index_col=0,\n",
    "                  #dtype for smaller representation\n",
    "                  dtype={'STAT_CAUSE_DESCR': 'category', 'STATE': 'category', 'DISCOVERY_MONTH': 'category',\n",
    "                        'Fog': 'bool', 'FunnelCloud': 'bool', 'Hail': 'bool', 'Rain': 'bool',\n",
    "                        'Snow': 'bool', 'Thunder': 'bool'}\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['FIRE_YEAR']==2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DAY'] = (data['FIRE_YEAR']-1992)*365+data['DISCOVERY_DOY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values('DAY', ascending=True, kind='mergesort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = dict(zip(range(data.shape[0]),data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_time = data[[\"DAY\"]]\n",
    "attr_space = data[[\"LATITUDE\", \"LONGITUDE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Setting up...\nInitializing sparse matrix...\nCPU times: user 5.86 s, sys: 51.8 ms, total: 5.91 s\nWall time: 5.92 s\n"
    }
   ],
   "source": [
    "%%time\n",
    "Aboth_15 = get_A_both(attr_space, 1.0, attr_time, 1.01, blocksize=100,ordering=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/jime/wildfire_GNN/adj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('A_both_15_unsorted.pkl', 'rb') as f:\n",
    "    pickle.dump(Aboth_15, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('A_both_unordered.pkl', 'rb') as f:\n",
    "    old_Aboth = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<74491x74491 sparse matrix of type '<class 'numpy.float64'>'\n\twith 3543722 stored elements in Compressed Sparse Row format>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "Aboth_15-old_Aboth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "matrix([[0., 1., 0., ..., 0., 0., 0.]])"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "Aboth_sorted[1].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "matrix([[0., 1., 0., ..., 0., 0., 0.]])"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "Aboth[12017].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block(values, dist, row_start, row_end, col_start, col_end):\n",
    "    \n",
    "    N = values.shape[0]\n",
    "\n",
    "    # Get the relevant values for this block\n",
    "    #print(\"Get row/col vals\")\n",
    "    row_values = values[row_start:row_end, :]\n",
    "    col_values = values[col_start:col_end, :]\n",
    "\n",
    "    # Get distance matrix for this block\n",
    "    #print(\"Calculate distance\")\n",
    "    # use cuda implementation from stackoverflow\n",
    "    D = spatial.distance.cdist(row_values, col_values)\n",
    "\n",
    "    # Threshold it\n",
    "    #print(\"Threshold it\")\n",
    "    subA = D <= dist\n",
    "    \n",
    "    return subA\n",
    "\n",
    "def get_A_both(data_space, dist_space, data_time, dist_time, blocksize=10000, ordering=None):\n",
    "    \n",
    "    print(\"Setting up...\")\n",
    "    space_values = np.array(data_space.values)\n",
    "    time_values = np.array(data_time.values)\n",
    "    \n",
    "    # Dimensions should be be (N, K), even if K = 1 columns. Reshape if needed\n",
    "    if len(space_values.shape) == 1:\n",
    "        space_values = space_values.reshape((space_values.shape[0], 1))\n",
    "    if len(time_values.shape) == 1:\n",
    "        time_values = time_values.reshape((time_values.shape[0], 1))\n",
    "        \n",
    "    assert space_values.shape[0] == time_values.shape[0], \"Datasets must have same number of observations\"\n",
    "    N = space_values.shape[0]\n",
    "        \n",
    "    print(\"Initializing sparse matrix...\")\n",
    "    # Initialize sparse matrix\n",
    "    A = sparse.lil_matrix((N,N))\n",
    "    \n",
    "    # Divide-and-conquer: split the overall big adjacency matrix into\n",
    "    # blocksize x blocksize chunks, then use scipy's super-fast C implementation for distance matrix\n",
    "    for i in range(N // blocksize+1):\n",
    "        skip_row = False\n",
    "            \n",
    "        for j in range(i, N // blocksize+1):\n",
    "            \n",
    "            if skip_row:\n",
    "                continue\n",
    "            \n",
    "            # Make sure we don't go out of bounds if N isn't divisible by blocksize!\n",
    "            row_start = i * blocksize\n",
    "            row_end   = min((i+1) * blocksize, N-1)\n",
    "            col_start = j * blocksize\n",
    "            col_end   = min((j+1) * blocksize, N-1)\n",
    "            \n",
    "            sub_A_time = get_block(time_values, dist_time, row_start, row_end, col_start, col_end)\n",
    "            \n",
    "            if (sub_A_time == 0).all():\n",
    "                #print((i,j))\n",
    "                #print(\"No more non-zeroes column-wise on this row!  Skipping to next\")\n",
    "                skip_row = True\n",
    "                \n",
    "            sub_A_space = get_block(space_values, dist_space, row_start, row_end, col_start, col_end)\n",
    "            \n",
    "            # Insert into matrix\n",
    "            #print(\"Insert into matrix\")\n",
    "            subA = sub_A_time * sub_A_space            \n",
    "            \n",
    "            A[row_start:row_end, col_start:col_end] = subA\n",
    "            \n",
    "            # This graph is undirected--A will be symmetric! So set the other side now\n",
    "            #if i != j:\n",
    "                #print(\"Insert into matrix, transposed\")\n",
    "                #A[col_start:col_end, row_start:row_end] = subA.T\n",
    "\n",
    "    # Convert to CSR format for fast arithmetic\n",
    "    if ordering!=None:\n",
    "        row = np.array(sparse.find(A)[0])\n",
    "        row = [ordering[i] for i in row]\n",
    "        col = np.array(sparse.find(A)[1])\n",
    "        entries = np.array(sparse.find(A)[2])\n",
    "        A = sparse.csr_matrix( (entries, (row,col)), shape=(A.shape[0],A.shape[1]) )\n",
    "    else:\n",
    "        A = A.tocsr()\n",
    "    \n",
    "    # This graph is undirected--so set the other side to be symmetric\n",
    "    # Do this efficiently by adding the transpose, and then removing the elements equal to 2 to 1\n",
    "    A += A.T\n",
    "    A[A == 2] = 1\n",
    "            \n",
    "    return A"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bittfgpu2condacfaed5e8fca7484ea62fc995be575eea",
   "display_name": "Python 3.7.7 64-bit ('tf_gpu2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}