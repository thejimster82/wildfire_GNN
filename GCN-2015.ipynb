{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN runner\n",
    "## Mark Tenzer & Jimmy Howerton\n",
    "## Adapted from code provided with the Spektral package, cited below:\n",
    "https://github.com/danielegrattarola/spektral/blob/master/examples/node_prediction/citation_gcn.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base python\n",
    "import pickle # for loading sparse matrix from disk\n",
    "import gc     # for garbage collection (RAM management/cleanup)\n",
    "\n",
    "# Common scientific packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TF imports\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Spektral imports for GNN\n",
    "from spektral.layers import GraphConv, GraphSageConv, GINConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of graph convolution\n",
    "Conv = GraphConv\n",
    "\n",
    "# File location to save model\n",
    "modelfile = \"GCN-2015.h5\"\n",
    "\n",
    "# Number of graph convolution layers\n",
    "n_layers = 5\n",
    "\n",
    "# Number of channels at each conv\n",
    "channels = 64\n",
    "\n",
    "# Adjacency matrix of choice\n",
    "adj_file = \"Aboth.pkl\"\n",
    "\n",
    "# Maximum number of training epochs\n",
    "epochs = 500\n",
    "\n",
    "# Dropout rate\n",
    "# dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the adjacency matrix $A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load $A$ from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(adj_file, 'rb') as f:\n",
    "    A = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess $A$ as needed for this GNN convolution technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltr = Conv.preprocess(A.astype('float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial read of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3051: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/mark/.local/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/mnt/d/wildfires/fires_merged_weather.csv', index_col=0,\n",
    "                  #dtype for smaller representation\n",
    "                  dtype={#'STAT_CAUSE_DESCR': 'category', 'STATE': 'category', 'DISCOVERY_MONTH': 'category',\n",
    "                        'Fog': 'bool', 'FunnelCloud': 'bool', 'Hail': 'bool', 'Rain': 'bool',\n",
    "                        'Snow': 'bool', 'Thunder': 'bool'}\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 0.1', 'index_x', 'FOD_ID', 'FIRE_NAME', 'DISCOVERY_DOY_SCALED',\n",
    "           'x_fire', 'y_fire', 'z_fire',\n",
    "           'index_y', 'Begin', 'End', 'Country', 'Day', 'ICAO', 'Latitude', 'Longitude', 'Month', 'STATION NAME',\n",
    "           'State', 'Station', 'USAF', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1', \n",
    "           'WBAN', 'Year', 'doy', 'x', 'y', 'z',\n",
    "          ],\n",
    "         axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just 2015 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.FIRE_YEAR == 2015]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanup memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data\n",
    "\n",
    "Perform imputation as appropriate; split into train/validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(data['STAT_CAUSE_DESCR'])\n",
    "X = pd.get_dummies(data.drop('STAT_CAUSE_DESCR', axis='columns'))\n",
    "\n",
    "# Number of examples\n",
    "N = X.shape[0]\n",
    "# Number of features\n",
    "F = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the missing values, and set to NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for na in [9999.9, 999.9, 99.99]:\n",
    "    X[X == na] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero-imputing for some features -- see EDA.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for zcol in ['Gust', 'MaxWindspeed', 'Precip', 'SnowDepth', 'Visibility', 'Windspeed']:\n",
    "    X.loc[X[zcol].isna(), zcol] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into training/testing\n",
    "\n",
    "We'll have three sets of nodes: training nodes, validation nodes, and censored nodes (nodes without valid labels).  Note that this is a semi-supervised problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine which nodes lack valid labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determing which fires fit in these categories\n",
    "censor = (data['STAT_CAUSE_DESCR'] == 'Missing/Undefined') | (data['STAT_CAUSE_DESCR'] == 'Miscellaneous')\n",
    "\n",
    "# Drop these levels from the label\n",
    "Y = Y.drop(['Missing/Undefined', 'Miscellaneous'], axis='columns').values\n",
    "\n",
    "# Number of classes left\n",
    "n_classes = Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_ind  = np.arange(data.shape[0])[~censor]\n",
    "censor_ind = np.arange(data.shape[0])[censor ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine which nodes lack valid labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind, val_ind = train_test_split(labeled_ind, test_size=0.1, random_state=42)\n",
    "\n",
    "# \"Masks\" for training and validation: 1 if in the given set, 0 if not (or no label)\n",
    "train_mask = np.zeros(N)\n",
    "train_mask[train_ind] = 1\n",
    "\n",
    "val_mask = np.zeros(N)\n",
    "val_mask[val_ind] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean imputation for the other features -- see EDA.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "              missing_values=nan, strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure to fit only on the training data!  Otherwise the imputation introduces bias\n",
    "imp.fit(X.values[train_ind, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the training and testing values\n",
    "X = imp.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "X_in = Input(shape=(F, ))           # features  for this node\n",
    "fltr_in = Input((N, ), sparse=True) # adjacency for this node\n",
    "\n",
    "currentX = X_in\n",
    "\n",
    "# For each of the specified layers, except the last,\n",
    "for _ in range(n_layers - 1):\n",
    "\n",
    "    # Dropout the current layer's inputs\n",
    "    #currentX = Dropout(dropout_rate)(currentX)\n",
    "    \n",
    "    # Graph convolution -- Note that \"Conv\" type was specified in Config section\n",
    "    currentX = Conv(channels,\n",
    "                      activation='relu',\n",
    "                      #kernel_regularizer=l2(0.1),\n",
    "                      #use_bias=False\n",
    "                     )([currentX, fltr_in])\n",
    "    \n",
    "    #currentX = BatchNormalization()(currentX)\n",
    "\n",
    "# Final layer: same approach, except:\n",
    "# instead of n_channels filters, use n_classes so we'll have one probability per class\n",
    "# instead of ReLU activation     use softmax   so we'll have a probability vector summing to 1\n",
    "#currentX = Dropout(dropout_rate)(currentX)\n",
    "\n",
    "output = Conv(n_classes,\n",
    "              activation='softmax',\n",
    "              #use_bias=False\n",
    "             )([currentX, fltr_in])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 83)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv (GraphConv)          (None, 64)           5376        input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_1 (GraphConv)        (None, 64)           4160        graph_conv[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_2 (GraphConv)        (None, 64)           4160        graph_conv_1[0][0]               \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_3 (GraphConv)        (None, 64)           4160        graph_conv_2[0][0]               \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_4 (GraphConv)        (None, 11)           715         graph_conv_3[0][0]               \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 18,571\n",
      "Trainable params: 18,571\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Model(inputs=[X_in, fltr_in], outputs=output)\n",
    "model.compile(optimizer=Adam(1e-2),\n",
    "              loss='categorical_crossentropy',\n",
    "              weighted_metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 74491 samples, validate on 74491 samples\n",
      "Epoch 1/500\n",
      "74491/74491 [==============================] - 4s 54us/sample - loss: 92.0733 - categorical_accuracy: 0.0413 - val_loss: 5.0470 - val_categorical_accuracy: 0.1152\n",
      "Epoch 2/500\n",
      "74491/74491 [==============================] - 2s 31us/sample - loss: 45.2969 - categorical_accuracy: 0.1170 - val_loss: 5.0137 - val_categorical_accuracy: 0.0962\n",
      "Epoch 3/500\n",
      "74491/74491 [==============================] - 2s 31us/sample - loss: 45.9036 - categorical_accuracy: 0.1003 - val_loss: 4.7422 - val_categorical_accuracy: 0.3597\n",
      "Epoch 4/500\n",
      "74491/74491 [==============================] - 2s 33us/sample - loss: 44.5231 - categorical_accuracy: 0.3598 - val_loss: 4.8490 - val_categorical_accuracy: 0.2020\n",
      "Epoch 5/500\n",
      "74491/74491 [==============================] - 2s 32us/sample - loss: 45.3741 - categorical_accuracy: 0.1952 - val_loss: 5.2236 - val_categorical_accuracy: 0.1349\n",
      "Epoch 6/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 47.9917 - categorical_accuracy: 0.1344 - val_loss: 5.9218 - val_categorical_accuracy: 0.3770\n",
      "Epoch 7/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 53.9815 - categorical_accuracy: 0.3707 - val_loss: 5.0814 - val_categorical_accuracy: 0.0930\n",
      "Epoch 8/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 46.2066 - categorical_accuracy: 0.0924 - val_loss: 4.4736 - val_categorical_accuracy: 0.0459\n",
      "Epoch 9/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 40.7688 - categorical_accuracy: 0.0449 - val_loss: 3.2090 - val_categorical_accuracy: 0.3816\n",
      "Epoch 10/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 29.3027 - categorical_accuracy: 0.3734 - val_loss: 2.5861 - val_categorical_accuracy: 0.1060\n",
      "Epoch 11/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 23.6493 - categorical_accuracy: 0.1065 - val_loss: 2.0684 - val_categorical_accuracy: 0.4741\n",
      "Epoch 12/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 19.0306 - categorical_accuracy: 0.4617 - val_loss: 1.6209 - val_categorical_accuracy: 0.4774\n",
      "Epoch 13/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 15.0249 - categorical_accuracy: 0.4646 - val_loss: 1.3279 - val_categorical_accuracy: 0.1509\n",
      "Epoch 14/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 12.4289 - categorical_accuracy: 0.1469 - val_loss: 1.0180 - val_categorical_accuracy: 0.3908\n",
      "Epoch 15/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 9.6403 - categorical_accuracy: 0.3846 - val_loss: 0.8468 - val_categorical_accuracy: 0.4800\n",
      "Epoch 16/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 8.0389 - categorical_accuracy: 0.4668 - val_loss: 0.5898 - val_categorical_accuracy: 0.4772\n",
      "Epoch 17/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 5.6386 - categorical_accuracy: 0.4635 - val_loss: 0.4576 - val_categorical_accuracy: 0.2581\n",
      "Epoch 18/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 4.3448 - categorical_accuracy: 0.2496 - val_loss: 0.3669 - val_categorical_accuracy: 0.1467\n",
      "Epoch 19/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 3.4445 - categorical_accuracy: 0.1465 - val_loss: 0.2678 - val_categorical_accuracy: 0.1433\n",
      "Epoch 20/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 2.5268 - categorical_accuracy: 0.1426 - val_loss: 0.2410 - val_categorical_accuracy: 0.3758\n",
      "Epoch 21/500\n",
      "74491/74491 [==============================] - 2s 31us/sample - loss: 2.2935 - categorical_accuracy: 0.3658 - val_loss: 0.2525 - val_categorical_accuracy: 0.3387\n",
      "Epoch 22/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 2.3935 - categorical_accuracy: 0.3237 - val_loss: 0.2167 - val_categorical_accuracy: 0.3980\n",
      "Epoch 23/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 2.0529 - categorical_accuracy: 0.3902 - val_loss: 0.2039 - val_categorical_accuracy: 0.2339\n",
      "Epoch 24/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.8770 - categorical_accuracy: 0.2251 - val_loss: 0.1856 - val_categorical_accuracy: 0.2006\n",
      "Epoch 25/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 1.7354 - categorical_accuracy: 0.1945 - val_loss: 0.1755 - val_categorical_accuracy: 0.1609\n",
      "Epoch 26/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.6339 - categorical_accuracy: 0.1550 - val_loss: 0.1537 - val_categorical_accuracy: 0.3357\n",
      "Epoch 27/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.4310 - categorical_accuracy: 0.3241 - val_loss: 0.1476 - val_categorical_accuracy: 0.3549\n",
      "Epoch 28/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 1.3725 - categorical_accuracy: 0.3486 - val_loss: 0.1432 - val_categorical_accuracy: 0.3816\n",
      "Epoch 29/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.3301 - categorical_accuracy: 0.3761 - val_loss: 0.1364 - val_categorical_accuracy: 0.4122\n",
      "Epoch 30/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 1.2668 - categorical_accuracy: 0.3997 - val_loss: 0.1306 - val_categorical_accuracy: 0.4248\n",
      "Epoch 31/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.2118 - categorical_accuracy: 0.4148 - val_loss: 0.1282 - val_categorical_accuracy: 0.4236\n",
      "Epoch 32/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 1.1882 - categorical_accuracy: 0.4133 - val_loss: 0.1280 - val_categorical_accuracy: 0.4098\n",
      "Epoch 33/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.1843 - categorical_accuracy: 0.3992 - val_loss: 0.1279 - val_categorical_accuracy: 0.3978\n",
      "Epoch 34/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 1.1823 - categorical_accuracy: 0.3885 - val_loss: 0.1273 - val_categorical_accuracy: 0.3988\n",
      "Epoch 35/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 1.1752 - categorical_accuracy: 0.3905 - val_loss: 0.1254 - val_categorical_accuracy: 0.4172\n",
      "Epoch 36/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 1.1574 - categorical_accuracy: 0.4070 - val_loss: 0.1234 - val_categorical_accuracy: 0.4244\n",
      "Epoch 37/500\n",
      "74491/74491 [==============================] - 2s 31us/sample - loss: 1.1386 - categorical_accuracy: 0.4146 - val_loss: 0.1232 - val_categorical_accuracy: 0.4259\n",
      "Epoch 38/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 1.1365 - categorical_accuracy: 0.4170 - val_loss: 0.1236 - val_categorical_accuracy: 0.4253\n",
      "Epoch 39/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.1407 - categorical_accuracy: 0.4174 - val_loss: 0.1228 - val_categorical_accuracy: 0.4279\n",
      "Epoch 40/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 1.1336 - categorical_accuracy: 0.4201 - val_loss: 0.1214 - val_categorical_accuracy: 0.4267\n",
      "Epoch 41/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 1.1205 - categorical_accuracy: 0.4198 - val_loss: 0.1204 - val_categorical_accuracy: 0.4277\n",
      "Epoch 42/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 1.1124 - categorical_accuracy: 0.4216 - val_loss: 0.1201 - val_categorical_accuracy: 0.4653\n",
      "Epoch 43/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.1102 - categorical_accuracy: 0.4535 - val_loss: 0.1197 - val_categorical_accuracy: 0.4778\n",
      "Epoch 44/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 1.1067 - categorical_accuracy: 0.4672 - val_loss: 0.1186 - val_categorical_accuracy: 0.4804\n",
      "Epoch 45/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.0975 - categorical_accuracy: 0.4699 - val_loss: 0.1172 - val_categorical_accuracy: 0.4804\n",
      "Epoch 46/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.0855 - categorical_accuracy: 0.4712 - val_loss: 0.1160 - val_categorical_accuracy: 0.4846\n",
      "Epoch 47/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.0763 - categorical_accuracy: 0.4722 - val_loss: 0.1155 - val_categorical_accuracy: 0.4854\n",
      "Epoch 48/500\n",
      "74491/74491 [==============================] - 2s 31us/sample - loss: 1.0718 - categorical_accuracy: 0.4727 - val_loss: 0.1152 - val_categorical_accuracy: 0.4860\n",
      "Epoch 49/500\n",
      "74491/74491 [==============================] - 2s 31us/sample - loss: 1.0691 - categorical_accuracy: 0.4731 - val_loss: 0.1147 - val_categorical_accuracy: 0.4868\n",
      "Epoch 50/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 1.0645 - categorical_accuracy: 0.4741 - val_loss: 0.1139 - val_categorical_accuracy: 0.4846\n",
      "Epoch 51/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.0572 - categorical_accuracy: 0.4738 - val_loss: 0.1131 - val_categorical_accuracy: 0.4848\n",
      "Epoch 52/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 1.0501 - categorical_accuracy: 0.4734 - val_loss: 0.1127 - val_categorical_accuracy: 0.4844\n",
      "Epoch 53/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 1.0453 - categorical_accuracy: 0.4728 - val_loss: 0.1125 - val_categorical_accuracy: 0.4842\n",
      "Epoch 54/500\n",
      "74491/74491 [==============================] - 3s 34us/sample - loss: 1.0427 - categorical_accuracy: 0.4723 - val_loss: 0.1123 - val_categorical_accuracy: 0.4832\n",
      "Epoch 55/500\n",
      "74491/74491 [==============================] - 2s 33us/sample - loss: 1.0408 - categorical_accuracy: 0.4721 - val_loss: 0.1121 - val_categorical_accuracy: 0.4832\n",
      "Epoch 56/500\n",
      "74491/74491 [==============================] - 3s 34us/sample - loss: 1.0385 - categorical_accuracy: 0.4721 - val_loss: 0.1118 - val_categorical_accuracy: 0.4840\n",
      "Epoch 57/500\n",
      "74491/74491 [==============================] - 2s 34us/sample - loss: 1.0357 - categorical_accuracy: 0.4723 - val_loss: 0.1115 - val_categorical_accuracy: 0.4840\n",
      "Epoch 58/500\n",
      "74491/74491 [==============================] - 3s 34us/sample - loss: 1.0328 - categorical_accuracy: 0.4722 - val_loss: 0.1112 - val_categorical_accuracy: 0.4836\n",
      "Epoch 59/500\n",
      "74491/74491 [==============================] - 3s 34us/sample - loss: 1.0305 - categorical_accuracy: 0.4725 - val_loss: 0.1111 - val_categorical_accuracy: 0.4850\n",
      "Epoch 60/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 1.0289 - categorical_accuracy: 0.4731 - val_loss: 0.1109 - val_categorical_accuracy: 0.4852\n",
      "Epoch 61/500\n",
      "74491/74491 [==============================] - 2s 33us/sample - loss: 1.0279 - categorical_accuracy: 0.4739 - val_loss: 0.1108 - val_categorical_accuracy: 0.4854\n",
      "Epoch 62/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 1.0266 - categorical_accuracy: 0.4741 - val_loss: 0.1106 - val_categorical_accuracy: 0.4856\n",
      "Epoch 63/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.0247 - categorical_accuracy: 0.4740 - val_loss: 0.1104 - val_categorical_accuracy: 0.4860\n",
      "Epoch 64/500\n",
      "74491/74491 [==============================] - 2s 31us/sample - loss: 1.0225 - categorical_accuracy: 0.4742 - val_loss: 0.1103 - val_categorical_accuracy: 0.4862\n",
      "Epoch 65/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.0208 - categorical_accuracy: 0.4740 - val_loss: 0.1102 - val_categorical_accuracy: 0.4856\n",
      "Epoch 66/500\n",
      "74491/74491 [==============================] - 2s 31us/sample - loss: 1.0197 - categorical_accuracy: 0.4741 - val_loss: 0.1102 - val_categorical_accuracy: 0.4856\n",
      "Epoch 67/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.0188 - categorical_accuracy: 0.4741 - val_loss: 0.1101 - val_categorical_accuracy: 0.4860\n",
      "Epoch 68/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.0179 - categorical_accuracy: 0.4741 - val_loss: 0.1100 - val_categorical_accuracy: 0.4864\n",
      "Epoch 69/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.0166 - categorical_accuracy: 0.4745 - val_loss: 0.1098 - val_categorical_accuracy: 0.4870\n",
      "Epoch 70/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.0152 - categorical_accuracy: 0.4752 - val_loss: 0.1097 - val_categorical_accuracy: 0.4878\n",
      "Epoch 71/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.0140 - categorical_accuracy: 0.4759 - val_loss: 0.1096 - val_categorical_accuracy: 0.4876\n",
      "Epoch 72/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.0135 - categorical_accuracy: 0.4761 - val_loss: 0.1095 - val_categorical_accuracy: 0.4880\n",
      "Epoch 73/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.0128 - categorical_accuracy: 0.4762 - val_loss: 0.1095 - val_categorical_accuracy: 0.4870\n",
      "Epoch 74/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.0121 - categorical_accuracy: 0.4760 - val_loss: 0.1094 - val_categorical_accuracy: 0.4872\n",
      "Epoch 75/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 1.0113 - categorical_accuracy: 0.4761 - val_loss: 0.1093 - val_categorical_accuracy: 0.4876\n",
      "Epoch 76/500\n",
      "74491/74491 [==============================] - 2s 31us/sample - loss: 1.0104 - categorical_accuracy: 0.4766 - val_loss: 0.1093 - val_categorical_accuracy: 0.4878\n",
      "Epoch 77/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 1.0095 - categorical_accuracy: 0.4769 - val_loss: 0.1092 - val_categorical_accuracy: 0.4878\n",
      "Epoch 78/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 1.0088 - categorical_accuracy: 0.4768 - val_loss: 0.1091 - val_categorical_accuracy: 0.4876\n",
      "Epoch 79/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 1.0081 - categorical_accuracy: 0.4768 - val_loss: 0.1091 - val_categorical_accuracy: 0.4878\n",
      "Epoch 80/500\n",
      "74491/74491 [==============================] - 2s 31us/sample - loss: 1.0074 - categorical_accuracy: 0.4769 - val_loss: 0.1090 - val_categorical_accuracy: 0.4874\n",
      "Epoch 81/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.0067 - categorical_accuracy: 0.4767 - val_loss: 0.1089 - val_categorical_accuracy: 0.4874\n",
      "Epoch 82/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 1.0058 - categorical_accuracy: 0.4768 - val_loss: 0.1088 - val_categorical_accuracy: 0.4894\n",
      "Epoch 83/500\n",
      "74491/74491 [==============================] - 2s 32us/sample - loss: 1.0048 - categorical_accuracy: 0.4776 - val_loss: 0.1086 - val_categorical_accuracy: 0.4902\n",
      "Epoch 84/500\n",
      "74491/74491 [==============================] - 2s 33us/sample - loss: 1.0031 - categorical_accuracy: 0.4790 - val_loss: 0.1086 - val_categorical_accuracy: 0.4908\n",
      "Epoch 85/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 1.0029 - categorical_accuracy: 0.4797 - val_loss: 0.1085 - val_categorical_accuracy: 0.4898\n",
      "Epoch 86/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 1.0010 - categorical_accuracy: 0.4792 - val_loss: 0.1085 - val_categorical_accuracy: 0.4900\n",
      "Epoch 87/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 1.0008 - categorical_accuracy: 0.4790 - val_loss: 0.1084 - val_categorical_accuracy: 0.4904\n",
      "Epoch 88/500\n",
      "74491/74491 [==============================] - 2s 31us/sample - loss: 0.9993 - categorical_accuracy: 0.4795 - val_loss: 0.1084 - val_categorical_accuracy: 0.4906\n",
      "Epoch 89/500\n",
      "74491/74491 [==============================] - 2s 33us/sample - loss: 0.9993 - categorical_accuracy: 0.4806 - val_loss: 0.1082 - val_categorical_accuracy: 0.4908\n",
      "Epoch 90/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9979 - categorical_accuracy: 0.4802 - val_loss: 0.1082 - val_categorical_accuracy: 0.4910\n",
      "Epoch 91/500\n",
      "74491/74491 [==============================] - 2s 31us/sample - loss: 0.9978 - categorical_accuracy: 0.4803 - val_loss: 0.1081 - val_categorical_accuracy: 0.4912\n",
      "Epoch 92/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9968 - categorical_accuracy: 0.4803 - val_loss: 0.1081 - val_categorical_accuracy: 0.4916\n",
      "Epoch 93/500\n",
      "74491/74491 [==============================] - 3s 34us/sample - loss: 0.9964 - categorical_accuracy: 0.4815 - val_loss: 0.1079 - val_categorical_accuracy: 0.4918\n",
      "Epoch 94/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9953 - categorical_accuracy: 0.4816 - val_loss: 0.1079 - val_categorical_accuracy: 0.4928\n",
      "Epoch 95/500\n",
      "74491/74491 [==============================] - 2s 31us/sample - loss: 0.9945 - categorical_accuracy: 0.4811 - val_loss: 0.1078 - val_categorical_accuracy: 0.4934\n",
      "Epoch 96/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9934 - categorical_accuracy: 0.4818 - val_loss: 0.1077 - val_categorical_accuracy: 0.4932\n",
      "Epoch 97/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9925 - categorical_accuracy: 0.4836 - val_loss: 0.1077 - val_categorical_accuracy: 0.4936\n",
      "Epoch 98/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9916 - categorical_accuracy: 0.4841 - val_loss: 0.1076 - val_categorical_accuracy: 0.4938\n",
      "Epoch 99/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9906 - categorical_accuracy: 0.4832 - val_loss: 0.1075 - val_categorical_accuracy: 0.4934\n",
      "Epoch 100/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9896 - categorical_accuracy: 0.4836 - val_loss: 0.1074 - val_categorical_accuracy: 0.4950\n",
      "Epoch 101/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9886 - categorical_accuracy: 0.4860 - val_loss: 0.1073 - val_categorical_accuracy: 0.4954\n",
      "Epoch 102/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9879 - categorical_accuracy: 0.4871 - val_loss: 0.1072 - val_categorical_accuracy: 0.4960\n",
      "Epoch 103/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9871 - categorical_accuracy: 0.4867 - val_loss: 0.1072 - val_categorical_accuracy: 0.4970\n",
      "Epoch 104/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9864 - categorical_accuracy: 0.4876 - val_loss: 0.1071 - val_categorical_accuracy: 0.4984\n",
      "Epoch 105/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9856 - categorical_accuracy: 0.4907 - val_loss: 0.1070 - val_categorical_accuracy: 0.4988\n",
      "Epoch 106/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9850 - categorical_accuracy: 0.4922 - val_loss: 0.1070 - val_categorical_accuracy: 0.5000\n",
      "Epoch 107/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9843 - categorical_accuracy: 0.4917 - val_loss: 0.1069 - val_categorical_accuracy: 0.5010\n",
      "Epoch 108/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9836 - categorical_accuracy: 0.4930 - val_loss: 0.1068 - val_categorical_accuracy: 0.5008\n",
      "Epoch 109/500\n",
      "74491/74491 [==============================] - 2s 32us/sample - loss: 0.9830 - categorical_accuracy: 0.4936 - val_loss: 0.1067 - val_categorical_accuracy: 0.5020\n",
      "Epoch 110/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9823 - categorical_accuracy: 0.4943 - val_loss: 0.1066 - val_categorical_accuracy: 0.5014\n",
      "Epoch 111/500\n",
      "74491/74491 [==============================] - 2s 32us/sample - loss: 0.9817 - categorical_accuracy: 0.4935 - val_loss: 0.1066 - val_categorical_accuracy: 0.5016\n",
      "Epoch 112/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9810 - categorical_accuracy: 0.4946 - val_loss: 0.1065 - val_categorical_accuracy: 0.5028\n",
      "Epoch 113/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9805 - categorical_accuracy: 0.4951 - val_loss: 0.1064 - val_categorical_accuracy: 0.5036\n",
      "Epoch 114/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 0.9798 - categorical_accuracy: 0.4953 - val_loss: 0.1064 - val_categorical_accuracy: 0.5036\n",
      "Epoch 115/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9793 - categorical_accuracy: 0.4956 - val_loss: 0.1063 - val_categorical_accuracy: 0.5034\n",
      "Epoch 116/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9787 - categorical_accuracy: 0.4954 - val_loss: 0.1063 - val_categorical_accuracy: 0.5038\n",
      "Epoch 117/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9781 - categorical_accuracy: 0.4958 - val_loss: 0.1062 - val_categorical_accuracy: 0.5056\n",
      "Epoch 118/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9776 - categorical_accuracy: 0.4964 - val_loss: 0.1061 - val_categorical_accuracy: 0.5058\n",
      "Epoch 119/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9769 - categorical_accuracy: 0.4968 - val_loss: 0.1061 - val_categorical_accuracy: 0.5062\n",
      "Epoch 120/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9763 - categorical_accuracy: 0.4973 - val_loss: 0.1060 - val_categorical_accuracy: 0.5064\n",
      "Epoch 121/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9758 - categorical_accuracy: 0.4976 - val_loss: 0.1060 - val_categorical_accuracy: 0.5068\n",
      "Epoch 122/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9752 - categorical_accuracy: 0.4977 - val_loss: 0.1059 - val_categorical_accuracy: 0.5064\n",
      "Epoch 123/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9746 - categorical_accuracy: 0.4974 - val_loss: 0.1059 - val_categorical_accuracy: 0.5076\n",
      "Epoch 124/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9740 - categorical_accuracy: 0.4976 - val_loss: 0.1058 - val_categorical_accuracy: 0.5066\n",
      "Epoch 125/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9734 - categorical_accuracy: 0.4976 - val_loss: 0.1057 - val_categorical_accuracy: 0.5048\n",
      "Epoch 126/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9727 - categorical_accuracy: 0.4976 - val_loss: 0.1056 - val_categorical_accuracy: 0.5068\n",
      "Epoch 127/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 0.9721 - categorical_accuracy: 0.4983 - val_loss: 0.1056 - val_categorical_accuracy: 0.5066\n",
      "Epoch 128/500\n",
      "74491/74491 [==============================] - 2s 32us/sample - loss: 0.9715 - categorical_accuracy: 0.4990 - val_loss: 0.1055 - val_categorical_accuracy: 0.5052\n",
      "Epoch 129/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9709 - categorical_accuracy: 0.4989 - val_loss: 0.1054 - val_categorical_accuracy: 0.5062\n",
      "Epoch 130/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9703 - categorical_accuracy: 0.4999 - val_loss: 0.1054 - val_categorical_accuracy: 0.5060\n",
      "Epoch 131/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9697 - categorical_accuracy: 0.4999 - val_loss: 0.1053 - val_categorical_accuracy: 0.5052\n",
      "Epoch 132/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9691 - categorical_accuracy: 0.4993 - val_loss: 0.1053 - val_categorical_accuracy: 0.5058\n",
      "Epoch 133/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9684 - categorical_accuracy: 0.4998 - val_loss: 0.1052 - val_categorical_accuracy: 0.5046\n",
      "Epoch 134/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 0.9678 - categorical_accuracy: 0.4998 - val_loss: 0.1052 - val_categorical_accuracy: 0.5036\n",
      "Epoch 135/500\n",
      "74491/74491 [==============================] - 2s 32us/sample - loss: 0.9672 - categorical_accuracy: 0.4996 - val_loss: 0.1052 - val_categorical_accuracy: 0.5050\n",
      "Epoch 136/500\n",
      "74491/74491 [==============================] - 3s 36us/sample - loss: 0.9666 - categorical_accuracy: 0.5008 - val_loss: 0.1051 - val_categorical_accuracy: 0.5050\n",
      "Epoch 137/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 0.9661 - categorical_accuracy: 0.5008 - val_loss: 0.1050 - val_categorical_accuracy: 0.5048\n",
      "Epoch 138/500\n",
      "74491/74491 [==============================] - 2s 31us/sample - loss: 0.9654 - categorical_accuracy: 0.5010 - val_loss: 0.1049 - val_categorical_accuracy: 0.5050\n",
      "Epoch 139/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9648 - categorical_accuracy: 0.5014 - val_loss: 0.1049 - val_categorical_accuracy: 0.5046\n",
      "Epoch 140/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9643 - categorical_accuracy: 0.5008 - val_loss: 0.1049 - val_categorical_accuracy: 0.5054\n",
      "Epoch 141/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9637 - categorical_accuracy: 0.5015 - val_loss: 0.1048 - val_categorical_accuracy: 0.5048\n",
      "Epoch 142/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9632 - categorical_accuracy: 0.5008 - val_loss: 0.1047 - val_categorical_accuracy: 0.5064\n",
      "Epoch 143/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9626 - categorical_accuracy: 0.5018 - val_loss: 0.1046 - val_categorical_accuracy: 0.5056\n",
      "Epoch 144/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9620 - categorical_accuracy: 0.5015 - val_loss: 0.1046 - val_categorical_accuracy: 0.5084\n",
      "Epoch 145/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9616 - categorical_accuracy: 0.5022 - val_loss: 0.1045 - val_categorical_accuracy: 0.5074\n",
      "Epoch 146/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9611 - categorical_accuracy: 0.5013 - val_loss: 0.1045 - val_categorical_accuracy: 0.5064\n",
      "Epoch 147/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9604 - categorical_accuracy: 0.5029 - val_loss: 0.1045 - val_categorical_accuracy: 0.5056\n",
      "Epoch 148/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9604 - categorical_accuracy: 0.4999 - val_loss: 0.1044 - val_categorical_accuracy: 0.5094\n",
      "Epoch 149/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9604 - categorical_accuracy: 0.5037 - val_loss: 0.1043 - val_categorical_accuracy: 0.5070\n",
      "Epoch 150/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9606 - categorical_accuracy: 0.5004 - val_loss: 0.1045 - val_categorical_accuracy: 0.5110\n",
      "Epoch 151/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9608 - categorical_accuracy: 0.5045 - val_loss: 0.1043 - val_categorical_accuracy: 0.5056\n",
      "Epoch 152/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9604 - categorical_accuracy: 0.5001 - val_loss: 0.1044 - val_categorical_accuracy: 0.5112\n",
      "Epoch 153/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9599 - categorical_accuracy: 0.5050 - val_loss: 0.1042 - val_categorical_accuracy: 0.5076\n",
      "Epoch 154/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9589 - categorical_accuracy: 0.5008 - val_loss: 0.1042 - val_categorical_accuracy: 0.5098\n",
      "Epoch 155/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9580 - categorical_accuracy: 0.5047 - val_loss: 0.1041 - val_categorical_accuracy: 0.5078\n",
      "Epoch 156/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9573 - categorical_accuracy: 0.5020 - val_loss: 0.1040 - val_categorical_accuracy: 0.5108\n",
      "Epoch 157/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9563 - categorical_accuracy: 0.5039 - val_loss: 0.1039 - val_categorical_accuracy: 0.5104\n",
      "Epoch 158/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9557 - categorical_accuracy: 0.5036 - val_loss: 0.1039 - val_categorical_accuracy: 0.5084\n",
      "Epoch 159/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9552 - categorical_accuracy: 0.5029 - val_loss: 0.1039 - val_categorical_accuracy: 0.5114\n",
      "Epoch 160/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9550 - categorical_accuracy: 0.5056 - val_loss: 0.1038 - val_categorical_accuracy: 0.5088\n",
      "Epoch 161/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9551 - categorical_accuracy: 0.5019 - val_loss: 0.1041 - val_categorical_accuracy: 0.5132\n",
      "Epoch 162/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9560 - categorical_accuracy: 0.5063 - val_loss: 0.1041 - val_categorical_accuracy: 0.5030\n",
      "Epoch 163/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9575 - categorical_accuracy: 0.4988 - val_loss: 0.1048 - val_categorical_accuracy: 0.5114\n",
      "Epoch 164/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9606 - categorical_accuracy: 0.5059 - val_loss: 0.1039 - val_categorical_accuracy: 0.5054\n",
      "Epoch 165/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9556 - categorical_accuracy: 0.5010 - val_loss: 0.1036 - val_categorical_accuracy: 0.5122\n",
      "Epoch 166/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9529 - categorical_accuracy: 0.5053 - val_loss: 0.1039 - val_categorical_accuracy: 0.5126\n",
      "Epoch 167/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9542 - categorical_accuracy: 0.5068 - val_loss: 0.1040 - val_categorical_accuracy: 0.5034\n",
      "Epoch 168/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9565 - categorical_accuracy: 0.4988 - val_loss: 0.1044 - val_categorical_accuracy: 0.5124\n",
      "Epoch 169/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9583 - categorical_accuracy: 0.5060 - val_loss: 0.1038 - val_categorical_accuracy: 0.5072\n",
      "Epoch 170/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9550 - categorical_accuracy: 0.5010 - val_loss: 0.1036 - val_categorical_accuracy: 0.5136\n",
      "Epoch 171/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9514 - categorical_accuracy: 0.5064 - val_loss: 0.1037 - val_categorical_accuracy: 0.5116\n",
      "Epoch 172/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9518 - categorical_accuracy: 0.5055 - val_loss: 0.1038 - val_categorical_accuracy: 0.5034\n",
      "Epoch 173/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9538 - categorical_accuracy: 0.4996 - val_loss: 0.1042 - val_categorical_accuracy: 0.5134\n",
      "Epoch 174/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9562 - categorical_accuracy: 0.5071 - val_loss: 0.1034 - val_categorical_accuracy: 0.5100\n",
      "Epoch 175/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9512 - categorical_accuracy: 0.5043 - val_loss: 0.1032 - val_categorical_accuracy: 0.5108\n",
      "Epoch 176/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9493 - categorical_accuracy: 0.5045 - val_loss: 0.1038 - val_categorical_accuracy: 0.5122\n",
      "Epoch 177/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9528 - categorical_accuracy: 0.5073 - val_loss: 0.1044 - val_categorical_accuracy: 0.4962\n",
      "Epoch 178/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9596 - categorical_accuracy: 0.4948 - val_loss: 0.1058 - val_categorical_accuracy: 0.5058\n",
      "Epoch 179/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9691 - categorical_accuracy: 0.5007 - val_loss: 0.1035 - val_categorical_accuracy: 0.5122\n",
      "Epoch 180/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9502 - categorical_accuracy: 0.5064 - val_loss: 0.1047 - val_categorical_accuracy: 0.4988\n",
      "Epoch 181/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9621 - categorical_accuracy: 0.4946 - val_loss: 0.1054 - val_categorical_accuracy: 0.5074\n",
      "Epoch 182/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9641 - categorical_accuracy: 0.5027 - val_loss: 0.1035 - val_categorical_accuracy: 0.5148\n",
      "Epoch 183/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9505 - categorical_accuracy: 0.5080 - val_loss: 0.1054 - val_categorical_accuracy: 0.4956\n",
      "Epoch 184/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9704 - categorical_accuracy: 0.4909 - val_loss: 0.1043 - val_categorical_accuracy: 0.5122\n",
      "Epoch 185/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9565 - categorical_accuracy: 0.5060 - val_loss: 0.1040 - val_categorical_accuracy: 0.5136\n",
      "Epoch 186/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9536 - categorical_accuracy: 0.5071 - val_loss: 0.1046 - val_categorical_accuracy: 0.4968\n",
      "Epoch 187/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9611 - categorical_accuracy: 0.4944 - val_loss: 0.1032 - val_categorical_accuracy: 0.5124\n",
      "Epoch 188/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9475 - categorical_accuracy: 0.5074 - val_loss: 0.1042 - val_categorical_accuracy: 0.5128\n",
      "Epoch 189/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9547 - categorical_accuracy: 0.5077 - val_loss: 0.1032 - val_categorical_accuracy: 0.5058\n",
      "Epoch 190/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9471 - categorical_accuracy: 0.5032 - val_loss: 0.1032 - val_categorical_accuracy: 0.5060\n",
      "Epoch 191/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9471 - categorical_accuracy: 0.5029 - val_loss: 0.1039 - val_categorical_accuracy: 0.5136\n",
      "Epoch 192/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9529 - categorical_accuracy: 0.5074 - val_loss: 0.1030 - val_categorical_accuracy: 0.5100\n",
      "Epoch 193/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9457 - categorical_accuracy: 0.5055 - val_loss: 0.1031 - val_categorical_accuracy: 0.5080\n",
      "Epoch 194/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9463 - categorical_accuracy: 0.5037 - val_loss: 0.1037 - val_categorical_accuracy: 0.5150\n",
      "Epoch 195/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9491 - categorical_accuracy: 0.5080 - val_loss: 0.1028 - val_categorical_accuracy: 0.5106\n",
      "Epoch 196/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9432 - categorical_accuracy: 0.5066 - val_loss: 0.1031 - val_categorical_accuracy: 0.5066\n",
      "Epoch 197/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9465 - categorical_accuracy: 0.5026 - val_loss: 0.1032 - val_categorical_accuracy: 0.5128\n",
      "Epoch 198/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9470 - categorical_accuracy: 0.5083 - val_loss: 0.1026 - val_categorical_accuracy: 0.5124\n",
      "Epoch 199/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9416 - categorical_accuracy: 0.5065 - val_loss: 0.1033 - val_categorical_accuracy: 0.5020\n",
      "Epoch 200/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9478 - categorical_accuracy: 0.4991 - val_loss: 0.1042 - val_categorical_accuracy: 0.5112\n",
      "Epoch 201/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9543 - categorical_accuracy: 0.5053 - val_loss: 0.1026 - val_categorical_accuracy: 0.5124\n",
      "Epoch 202/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 0.9425 - categorical_accuracy: 0.5075 - val_loss: 0.1037 - val_categorical_accuracy: 0.5004\n",
      "Epoch 203/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9525 - categorical_accuracy: 0.4986 - val_loss: 0.1039 - val_categorical_accuracy: 0.5128\n",
      "Epoch 204/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9515 - categorical_accuracy: 0.5071 - val_loss: 0.1030 - val_categorical_accuracy: 0.5152\n",
      "Epoch 205/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9444 - categorical_accuracy: 0.5086 - val_loss: 0.1040 - val_categorical_accuracy: 0.4976\n",
      "Epoch 206/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9559 - categorical_accuracy: 0.4959 - val_loss: 0.1027 - val_categorical_accuracy: 0.5150\n",
      "Epoch 207/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9426 - categorical_accuracy: 0.5089 - val_loss: 0.1033 - val_categorical_accuracy: 0.5130\n",
      "Epoch 208/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9471 - categorical_accuracy: 0.5081 - val_loss: 0.1031 - val_categorical_accuracy: 0.5054\n",
      "Epoch 209/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9472 - categorical_accuracy: 0.5015 - val_loss: 0.1024 - val_categorical_accuracy: 0.5120\n",
      "Epoch 210/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9398 - categorical_accuracy: 0.5069 - val_loss: 0.1033 - val_categorical_accuracy: 0.5128\n",
      "Epoch 211/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9461 - categorical_accuracy: 0.5075 - val_loss: 0.1023 - val_categorical_accuracy: 0.5106\n",
      "Epoch 212/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9390 - categorical_accuracy: 0.5063 - val_loss: 0.1026 - val_categorical_accuracy: 0.5080\n",
      "Epoch 213/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9420 - categorical_accuracy: 0.5035 - val_loss: 0.1029 - val_categorical_accuracy: 0.5138\n",
      "Epoch 214/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9434 - categorical_accuracy: 0.5086 - val_loss: 0.1021 - val_categorical_accuracy: 0.5130\n",
      "Epoch 215/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9369 - categorical_accuracy: 0.5081 - val_loss: 0.1030 - val_categorical_accuracy: 0.5030\n",
      "Epoch 216/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9440 - categorical_accuracy: 0.5011 - val_loss: 0.1034 - val_categorical_accuracy: 0.5136\n",
      "Epoch 217/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9473 - categorical_accuracy: 0.5080 - val_loss: 0.1021 - val_categorical_accuracy: 0.5130\n",
      "Epoch 218/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9369 - categorical_accuracy: 0.5080 - val_loss: 0.1033 - val_categorical_accuracy: 0.5000\n",
      "Epoch 219/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9475 - categorical_accuracy: 0.4988 - val_loss: 0.1036 - val_categorical_accuracy: 0.5138\n",
      "Epoch 220/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9489 - categorical_accuracy: 0.5072 - val_loss: 0.1023 - val_categorical_accuracy: 0.5156\n",
      "Epoch 221/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9376 - categorical_accuracy: 0.5090 - val_loss: 0.1036 - val_categorical_accuracy: 0.4994\n",
      "Epoch 222/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9511 - categorical_accuracy: 0.4966 - val_loss: 0.1026 - val_categorical_accuracy: 0.5136\n",
      "Epoch 223/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9410 - categorical_accuracy: 0.5084 - val_loss: 0.1027 - val_categorical_accuracy: 0.5134\n",
      "Epoch 224/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9415 - categorical_accuracy: 0.5085 - val_loss: 0.1029 - val_categorical_accuracy: 0.5062\n",
      "Epoch 225/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9440 - categorical_accuracy: 0.5018 - val_loss: 0.1020 - val_categorical_accuracy: 0.5128\n",
      "Epoch 226/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9354 - categorical_accuracy: 0.5076 - val_loss: 0.1028 - val_categorical_accuracy: 0.5132\n",
      "Epoch 227/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9422 - categorical_accuracy: 0.5085 - val_loss: 0.1019 - val_categorical_accuracy: 0.5114\n",
      "Epoch 228/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9356 - categorical_accuracy: 0.5066 - val_loss: 0.1021 - val_categorical_accuracy: 0.5098\n",
      "Epoch 229/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9370 - categorical_accuracy: 0.5054 - val_loss: 0.1025 - val_categorical_accuracy: 0.5142\n",
      "Epoch 230/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9394 - categorical_accuracy: 0.5089 - val_loss: 0.1018 - val_categorical_accuracy: 0.5128\n",
      "Epoch 231/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9335 - categorical_accuracy: 0.5082 - val_loss: 0.1022 - val_categorical_accuracy: 0.5078\n",
      "Epoch 232/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9372 - categorical_accuracy: 0.5041 - val_loss: 0.1026 - val_categorical_accuracy: 0.5154\n",
      "Epoch 233/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9400 - categorical_accuracy: 0.5094 - val_loss: 0.1017 - val_categorical_accuracy: 0.5142\n",
      "Epoch 234/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9336 - categorical_accuracy: 0.5083 - val_loss: 0.1022 - val_categorical_accuracy: 0.5060\n",
      "Epoch 235/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9375 - categorical_accuracy: 0.5033 - val_loss: 0.1028 - val_categorical_accuracy: 0.5146\n",
      "Epoch 236/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9408 - categorical_accuracy: 0.5089 - val_loss: 0.1016 - val_categorical_accuracy: 0.5140\n",
      "Epoch 237/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9332 - categorical_accuracy: 0.5084 - val_loss: 0.1023 - val_categorical_accuracy: 0.5052\n",
      "Epoch 238/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9386 - categorical_accuracy: 0.5023 - val_loss: 0.1027 - val_categorical_accuracy: 0.5146\n",
      "Epoch 239/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9407 - categorical_accuracy: 0.5087 - val_loss: 0.1016 - val_categorical_accuracy: 0.5158\n",
      "Epoch 240/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9325 - categorical_accuracy: 0.5098 - val_loss: 0.1026 - val_categorical_accuracy: 0.5034\n",
      "Epoch 241/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9406 - categorical_accuracy: 0.5012 - val_loss: 0.1024 - val_categorical_accuracy: 0.5146\n",
      "Epoch 242/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9382 - categorical_accuracy: 0.5092 - val_loss: 0.1016 - val_categorical_accuracy: 0.5166\n",
      "Epoch 243/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9322 - categorical_accuracy: 0.5103 - val_loss: 0.1026 - val_categorical_accuracy: 0.5036\n",
      "Epoch 244/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9410 - categorical_accuracy: 0.5013 - val_loss: 0.1019 - val_categorical_accuracy: 0.5156\n",
      "Epoch 245/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9343 - categorical_accuracy: 0.5092 - val_loss: 0.1016 - val_categorical_accuracy: 0.5154\n",
      "Epoch 246/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9315 - categorical_accuracy: 0.5105 - val_loss: 0.1023 - val_categorical_accuracy: 0.5060\n",
      "Epoch 247/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9383 - categorical_accuracy: 0.5020 - val_loss: 0.1016 - val_categorical_accuracy: 0.5158\n",
      "Epoch 248/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9317 - categorical_accuracy: 0.5101 - val_loss: 0.1016 - val_categorical_accuracy: 0.5158\n",
      "Epoch 249/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9311 - categorical_accuracy: 0.5095 - val_loss: 0.1020 - val_categorical_accuracy: 0.5078\n",
      "Epoch 250/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9360 - categorical_accuracy: 0.5031 - val_loss: 0.1015 - val_categorical_accuracy: 0.5160\n",
      "Epoch 251/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9310 - categorical_accuracy: 0.5104 - val_loss: 0.1014 - val_categorical_accuracy: 0.5168\n",
      "Epoch 252/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9299 - categorical_accuracy: 0.5095 - val_loss: 0.1018 - val_categorical_accuracy: 0.5092\n",
      "Epoch 253/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9341 - categorical_accuracy: 0.5047 - val_loss: 0.1014 - val_categorical_accuracy: 0.5162\n",
      "Epoch 254/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9300 - categorical_accuracy: 0.5102 - val_loss: 0.1013 - val_categorical_accuracy: 0.5162\n",
      "Epoch 255/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9290 - categorical_accuracy: 0.5100 - val_loss: 0.1017 - val_categorical_accuracy: 0.5090\n",
      "Epoch 256/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9339 - categorical_accuracy: 0.5062 - val_loss: 0.1013 - val_categorical_accuracy: 0.5164\n",
      "Epoch 257/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9283 - categorical_accuracy: 0.5105 - val_loss: 0.1012 - val_categorical_accuracy: 0.5162\n",
      "Epoch 258/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9278 - categorical_accuracy: 0.5102 - val_loss: 0.1016 - val_categorical_accuracy: 0.5100\n",
      "Epoch 259/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9330 - categorical_accuracy: 0.5067 - val_loss: 0.1011 - val_categorical_accuracy: 0.5162\n",
      "Epoch 260/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9270 - categorical_accuracy: 0.5100 - val_loss: 0.1010 - val_categorical_accuracy: 0.5166\n",
      "Epoch 261/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9258 - categorical_accuracy: 0.5102 - val_loss: 0.1014 - val_categorical_accuracy: 0.5104\n",
      "Epoch 262/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9302 - categorical_accuracy: 0.5071 - val_loss: 0.1012 - val_categorical_accuracy: 0.5170\n",
      "Epoch 263/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9274 - categorical_accuracy: 0.5098 - val_loss: 0.1007 - val_categorical_accuracy: 0.5172\n",
      "Epoch 264/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9243 - categorical_accuracy: 0.5103 - val_loss: 0.1010 - val_categorical_accuracy: 0.5132\n",
      "Epoch 265/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9263 - categorical_accuracy: 0.5084 - val_loss: 0.1012 - val_categorical_accuracy: 0.5168\n",
      "Epoch 266/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9279 - categorical_accuracy: 0.5102 - val_loss: 0.1009 - val_categorical_accuracy: 0.5156\n",
      "Epoch 267/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9253 - categorical_accuracy: 0.5087 - val_loss: 0.1007 - val_categorical_accuracy: 0.5184\n",
      "Epoch 268/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 0.9246 - categorical_accuracy: 0.5106 - val_loss: 0.1014 - val_categorical_accuracy: 0.5168\n",
      "Epoch 269/500\n",
      "74491/74491 [==============================] - 2s 32us/sample - loss: 0.9282 - categorical_accuracy: 0.5092 - val_loss: 0.1019 - val_categorical_accuracy: 0.5142\n",
      "Epoch 270/500\n",
      "74491/74491 [==============================] - 2s 32us/sample - loss: 0.9372 - categorical_accuracy: 0.5082 - val_loss: 0.1015 - val_categorical_accuracy: 0.5154\n",
      "Epoch 271/500\n",
      "74491/74491 [==============================] - 3s 34us/sample - loss: 0.9292 - categorical_accuracy: 0.5087 - val_loss: 0.1011 - val_categorical_accuracy: 0.5158\n",
      "Epoch 272/500\n",
      "74491/74491 [==============================] - 3s 36us/sample - loss: 0.9279 - categorical_accuracy: 0.5105 - val_loss: 0.1015 - val_categorical_accuracy: 0.5084\n",
      "Epoch 273/500\n",
      "74491/74491 [==============================] - 2s 32us/sample - loss: 0.9306 - categorical_accuracy: 0.5056 - val_loss: 0.1017 - val_categorical_accuracy: 0.5154\n",
      "Epoch 274/500\n",
      "74491/74491 [==============================] - 2s 31us/sample - loss: 0.9315 - categorical_accuracy: 0.5095 - val_loss: 0.1008 - val_categorical_accuracy: 0.5160\n",
      "Epoch 275/500\n",
      "74491/74491 [==============================] - 2s 31us/sample - loss: 0.9249 - categorical_accuracy: 0.5098 - val_loss: 0.1011 - val_categorical_accuracy: 0.5124\n",
      "Epoch 276/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9270 - categorical_accuracy: 0.5076 - val_loss: 0.1018 - val_categorical_accuracy: 0.5150\n",
      "Epoch 277/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9319 - categorical_accuracy: 0.5086 - val_loss: 0.1008 - val_categorical_accuracy: 0.5172\n",
      "Epoch 278/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9246 - categorical_accuracy: 0.5089 - val_loss: 0.1008 - val_categorical_accuracy: 0.5168\n",
      "Epoch 279/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9264 - categorical_accuracy: 0.5101 - val_loss: 0.1014 - val_categorical_accuracy: 0.5170\n",
      "Epoch 280/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9297 - categorical_accuracy: 0.5098 - val_loss: 0.1018 - val_categorical_accuracy: 0.5160\n",
      "Epoch 281/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9361 - categorical_accuracy: 0.5093 - val_loss: 0.1015 - val_categorical_accuracy: 0.5164\n",
      "Epoch 282/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9306 - categorical_accuracy: 0.5082 - val_loss: 0.1029 - val_categorical_accuracy: 0.5146\n",
      "Epoch 283/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9441 - categorical_accuracy: 0.5078 - val_loss: 0.1021 - val_categorical_accuracy: 0.5048\n",
      "Epoch 284/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9355 - categorical_accuracy: 0.5022 - val_loss: 0.1013 - val_categorical_accuracy: 0.5170\n",
      "Epoch 285/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9289 - categorical_accuracy: 0.5106 - val_loss: 0.1008 - val_categorical_accuracy: 0.5184\n",
      "Epoch 286/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9235 - categorical_accuracy: 0.5107 - val_loss: 0.1014 - val_categorical_accuracy: 0.5086\n",
      "Epoch 287/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9297 - categorical_accuracy: 0.5044 - val_loss: 0.1015 - val_categorical_accuracy: 0.5162\n",
      "Epoch 288/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9315 - categorical_accuracy: 0.5100 - val_loss: 0.1012 - val_categorical_accuracy: 0.5190\n",
      "Epoch 289/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 0.9275 - categorical_accuracy: 0.5104 - val_loss: 0.1014 - val_categorical_accuracy: 0.5138\n",
      "Epoch 290/500\n",
      "74491/74491 [==============================] - 2s 32us/sample - loss: 0.9315 - categorical_accuracy: 0.5068 - val_loss: 0.1012 - val_categorical_accuracy: 0.5180\n",
      "Epoch 291/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 0.9280 - categorical_accuracy: 0.5101 - val_loss: 0.1014 - val_categorical_accuracy: 0.5178\n",
      "Epoch 292/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9295 - categorical_accuracy: 0.5096 - val_loss: 0.1023 - val_categorical_accuracy: 0.5144\n",
      "Epoch 293/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9418 - categorical_accuracy: 0.5080 - val_loss: 0.1003 - val_categorical_accuracy: 0.5186\n",
      "Epoch 294/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9209 - categorical_accuracy: 0.5117 - val_loss: 0.1029 - val_categorical_accuracy: 0.5138\n",
      "Epoch 295/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9395 - categorical_accuracy: 0.5056 - val_loss: 0.1031 - val_categorical_accuracy: 0.5104\n",
      "Epoch 296/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9472 - categorical_accuracy: 0.5054 - val_loss: 0.1019 - val_categorical_accuracy: 0.5172\n",
      "Epoch 297/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9369 - categorical_accuracy: 0.5108 - val_loss: 0.1039 - val_categorical_accuracy: 0.5114\n",
      "Epoch 298/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9494 - categorical_accuracy: 0.5049 - val_loss: 0.1023 - val_categorical_accuracy: 0.5132\n",
      "Epoch 299/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9357 - categorical_accuracy: 0.5060 - val_loss: 0.1033 - val_categorical_accuracy: 0.5168\n",
      "Epoch 300/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9493 - categorical_accuracy: 0.5108 - val_loss: 0.1030 - val_categorical_accuracy: 0.5086\n",
      "Epoch 301/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9460 - categorical_accuracy: 0.5043 - val_loss: 0.1017 - val_categorical_accuracy: 0.5172\n",
      "Epoch 302/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9299 - categorical_accuracy: 0.5097 - val_loss: 0.1018 - val_categorical_accuracy: 0.5176\n",
      "Epoch 303/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9330 - categorical_accuracy: 0.5109 - val_loss: 0.1011 - val_categorical_accuracy: 0.5180\n",
      "Epoch 304/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9290 - categorical_accuracy: 0.5097 - val_loss: 0.1015 - val_categorical_accuracy: 0.5178\n",
      "Epoch 305/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9325 - categorical_accuracy: 0.5105 - val_loss: 0.1009 - val_categorical_accuracy: 0.5154\n",
      "Epoch 306/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9240 - categorical_accuracy: 0.5085 - val_loss: 0.1023 - val_categorical_accuracy: 0.5148\n",
      "Epoch 307/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9353 - categorical_accuracy: 0.5071 - val_loss: 0.1008 - val_categorical_accuracy: 0.5160\n",
      "Epoch 308/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9264 - categorical_accuracy: 0.5086 - val_loss: 0.1018 - val_categorical_accuracy: 0.5166\n",
      "Epoch 309/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9374 - categorical_accuracy: 0.5094 - val_loss: 0.1008 - val_categorical_accuracy: 0.5178\n",
      "Epoch 310/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9252 - categorical_accuracy: 0.5096 - val_loss: 0.1012 - val_categorical_accuracy: 0.5186\n",
      "Epoch 311/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9268 - categorical_accuracy: 0.5092 - val_loss: 0.1017 - val_categorical_accuracy: 0.5166\n",
      "Epoch 312/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9299 - categorical_accuracy: 0.5096 - val_loss: 0.1016 - val_categorical_accuracy: 0.5100\n",
      "Epoch 313/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9316 - categorical_accuracy: 0.5060 - val_loss: 0.1009 - val_categorical_accuracy: 0.5192\n",
      "Epoch 314/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9275 - categorical_accuracy: 0.5125 - val_loss: 0.1009 - val_categorical_accuracy: 0.5194\n",
      "Epoch 315/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9263 - categorical_accuracy: 0.5124 - val_loss: 0.1013 - val_categorical_accuracy: 0.5160\n",
      "Epoch 316/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9281 - categorical_accuracy: 0.5070 - val_loss: 0.1019 - val_categorical_accuracy: 0.5190\n",
      "Epoch 317/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9348 - categorical_accuracy: 0.5107 - val_loss: 0.1013 - val_categorical_accuracy: 0.5120\n",
      "Epoch 318/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9294 - categorical_accuracy: 0.5073 - val_loss: 0.1001 - val_categorical_accuracy: 0.5220\n",
      "Epoch 319/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9185 - categorical_accuracy: 0.5123 - val_loss: 0.1011 - val_categorical_accuracy: 0.5190\n",
      "Epoch 320/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9266 - categorical_accuracy: 0.5124 - val_loss: 0.1004 - val_categorical_accuracy: 0.5172\n",
      "Epoch 321/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9221 - categorical_accuracy: 0.5099 - val_loss: 0.1002 - val_categorical_accuracy: 0.5196\n",
      "Epoch 322/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9207 - categorical_accuracy: 0.5117 - val_loss: 0.1008 - val_categorical_accuracy: 0.5210\n",
      "Epoch 323/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9227 - categorical_accuracy: 0.5116 - val_loss: 0.1001 - val_categorical_accuracy: 0.5202\n",
      "Epoch 324/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9197 - categorical_accuracy: 0.5103 - val_loss: 0.1005 - val_categorical_accuracy: 0.5198\n",
      "Epoch 325/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9242 - categorical_accuracy: 0.5129 - val_loss: 0.1001 - val_categorical_accuracy: 0.5176\n",
      "Epoch 326/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 0.9177 - categorical_accuracy: 0.5110 - val_loss: 0.1000 - val_categorical_accuracy: 0.5214\n",
      "Epoch 327/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9164 - categorical_accuracy: 0.5121 - val_loss: 0.0999 - val_categorical_accuracy: 0.5208\n",
      "Epoch 328/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9165 - categorical_accuracy: 0.5120 - val_loss: 0.0996 - val_categorical_accuracy: 0.5206\n",
      "Epoch 329/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9139 - categorical_accuracy: 0.5122 - val_loss: 0.0999 - val_categorical_accuracy: 0.5218\n",
      "Epoch 330/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9163 - categorical_accuracy: 0.5129 - val_loss: 0.0999 - val_categorical_accuracy: 0.5182\n",
      "Epoch 331/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9170 - categorical_accuracy: 0.5111 - val_loss: 0.0999 - val_categorical_accuracy: 0.5226\n",
      "Epoch 332/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9166 - categorical_accuracy: 0.5137 - val_loss: 0.1013 - val_categorical_accuracy: 0.5162\n",
      "Epoch 333/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9270 - categorical_accuracy: 0.5093 - val_loss: 0.1050 - val_categorical_accuracy: 0.5088\n",
      "Epoch 334/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9670 - categorical_accuracy: 0.5017 - val_loss: 0.1024 - val_categorical_accuracy: 0.5058\n",
      "Epoch 335/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9376 - categorical_accuracy: 0.5012 - val_loss: 0.1036 - val_categorical_accuracy: 0.5148\n",
      "Epoch 336/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9460 - categorical_accuracy: 0.5068 - val_loss: 0.1012 - val_categorical_accuracy: 0.5166\n",
      "Epoch 337/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9296 - categorical_accuracy: 0.5105 - val_loss: 0.1031 - val_categorical_accuracy: 0.5034\n",
      "Epoch 338/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9455 - categorical_accuracy: 0.5010 - val_loss: 0.1028 - val_categorical_accuracy: 0.5140\n",
      "Epoch 339/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9408 - categorical_accuracy: 0.5067 - val_loss: 0.1022 - val_categorical_accuracy: 0.5158\n",
      "Epoch 340/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9354 - categorical_accuracy: 0.5095 - val_loss: 0.1020 - val_categorical_accuracy: 0.5072\n",
      "Epoch 341/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9359 - categorical_accuracy: 0.5034 - val_loss: 0.1010 - val_categorical_accuracy: 0.5154\n",
      "Epoch 342/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9276 - categorical_accuracy: 0.5120 - val_loss: 0.1018 - val_categorical_accuracy: 0.5162\n",
      "Epoch 343/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9315 - categorical_accuracy: 0.5090 - val_loss: 0.1018 - val_categorical_accuracy: 0.5090\n",
      "Epoch 344/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9314 - categorical_accuracy: 0.5034 - val_loss: 0.1013 - val_categorical_accuracy: 0.5156\n",
      "Epoch 345/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9311 - categorical_accuracy: 0.5106 - val_loss: 0.1000 - val_categorical_accuracy: 0.5202\n",
      "Epoch 346/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9176 - categorical_accuracy: 0.5129 - val_loss: 0.1022 - val_categorical_accuracy: 0.5120\n",
      "Epoch 347/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9351 - categorical_accuracy: 0.5069 - val_loss: 0.1015 - val_categorical_accuracy: 0.5178\n",
      "Epoch 348/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9323 - categorical_accuracy: 0.5098 - val_loss: 0.1000 - val_categorical_accuracy: 0.5176\n",
      "Epoch 349/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9191 - categorical_accuracy: 0.5108 - val_loss: 0.1013 - val_categorical_accuracy: 0.5112\n",
      "Epoch 350/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9276 - categorical_accuracy: 0.5048 - val_loss: 0.1034 - val_categorical_accuracy: 0.5134\n",
      "Epoch 351/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9464 - categorical_accuracy: 0.5045 - val_loss: 0.1007 - val_categorical_accuracy: 0.5164\n",
      "Epoch 352/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9253 - categorical_accuracy: 0.5093 - val_loss: 0.1022 - val_categorical_accuracy: 0.5074\n",
      "Epoch 353/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9377 - categorical_accuracy: 0.5038 - val_loss: 0.1020 - val_categorical_accuracy: 0.5168\n",
      "Epoch 354/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9344 - categorical_accuracy: 0.5079 - val_loss: 0.1020 - val_categorical_accuracy: 0.5158\n",
      "Epoch 355/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9342 - categorical_accuracy: 0.5079 - val_loss: 0.1005 - val_categorical_accuracy: 0.5158\n",
      "Epoch 356/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9225 - categorical_accuracy: 0.5075 - val_loss: 0.1009 - val_categorical_accuracy: 0.5178\n",
      "Epoch 357/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9273 - categorical_accuracy: 0.5089 - val_loss: 0.1008 - val_categorical_accuracy: 0.5198\n",
      "Epoch 358/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9249 - categorical_accuracy: 0.5115 - val_loss: 0.1008 - val_categorical_accuracy: 0.5210\n",
      "Epoch 359/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9230 - categorical_accuracy: 0.5113 - val_loss: 0.0998 - val_categorical_accuracy: 0.5214\n",
      "Epoch 360/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9179 - categorical_accuracy: 0.5120 - val_loss: 0.1001 - val_categorical_accuracy: 0.5218\n",
      "Epoch 361/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9202 - categorical_accuracy: 0.5127 - val_loss: 0.1022 - val_categorical_accuracy: 0.5186\n",
      "Epoch 362/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9351 - categorical_accuracy: 0.5101 - val_loss: 0.1019 - val_categorical_accuracy: 0.5164\n",
      "Epoch 363/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9372 - categorical_accuracy: 0.5105 - val_loss: 0.1010 - val_categorical_accuracy: 0.5112\n",
      "Epoch 364/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9270 - categorical_accuracy: 0.5062 - val_loss: 0.1006 - val_categorical_accuracy: 0.5204\n",
      "Epoch 365/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9219 - categorical_accuracy: 0.5112 - val_loss: 0.1004 - val_categorical_accuracy: 0.5190\n",
      "Epoch 366/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9200 - categorical_accuracy: 0.5116 - val_loss: 0.1009 - val_categorical_accuracy: 0.5100\n",
      "Epoch 367/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9246 - categorical_accuracy: 0.5070 - val_loss: 0.1002 - val_categorical_accuracy: 0.5228\n",
      "Epoch 368/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9203 - categorical_accuracy: 0.5139 - val_loss: 0.1007 - val_categorical_accuracy: 0.5232\n",
      "Epoch 369/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9224 - categorical_accuracy: 0.5144 - val_loss: 0.0999 - val_categorical_accuracy: 0.5222\n",
      "Epoch 370/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9158 - categorical_accuracy: 0.5123 - val_loss: 0.0999 - val_categorical_accuracy: 0.5214\n",
      "Epoch 371/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9176 - categorical_accuracy: 0.5133 - val_loss: 0.0996 - val_categorical_accuracy: 0.5216\n",
      "Epoch 372/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9130 - categorical_accuracy: 0.5122 - val_loss: 0.1003 - val_categorical_accuracy: 0.5178\n",
      "Epoch 373/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9187 - categorical_accuracy: 0.5104 - val_loss: 0.0994 - val_categorical_accuracy: 0.5214\n",
      "Epoch 374/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 0.9146 - categorical_accuracy: 0.5142 - val_loss: 0.0992 - val_categorical_accuracy: 0.5226\n",
      "Epoch 375/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9128 - categorical_accuracy: 0.5134 - val_loss: 0.1001 - val_categorical_accuracy: 0.5251\n",
      "Epoch 376/500\n",
      "74491/74491 [==============================] - 2s 29us/sample - loss: 0.9169 - categorical_accuracy: 0.5144 - val_loss: 0.1000 - val_categorical_accuracy: 0.5218\n",
      "Epoch 377/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9198 - categorical_accuracy: 0.5141 - val_loss: 0.1005 - val_categorical_accuracy: 0.5120\n",
      "Epoch 378/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9219 - categorical_accuracy: 0.5070 - val_loss: 0.1019 - val_categorical_accuracy: 0.5174\n",
      "Epoch 379/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9342 - categorical_accuracy: 0.5096 - val_loss: 0.0995 - val_categorical_accuracy: 0.5188\n",
      "Epoch 380/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9140 - categorical_accuracy: 0.5103 - val_loss: 0.0995 - val_categorical_accuracy: 0.5192\n",
      "Epoch 381/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9137 - categorical_accuracy: 0.5109 - val_loss: 0.1003 - val_categorical_accuracy: 0.5200\n",
      "Epoch 382/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9192 - categorical_accuracy: 0.5123 - val_loss: 0.0999 - val_categorical_accuracy: 0.5226\n",
      "Epoch 383/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9151 - categorical_accuracy: 0.5129 - val_loss: 0.1000 - val_categorical_accuracy: 0.5202\n",
      "Epoch 384/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9191 - categorical_accuracy: 0.5119 - val_loss: 0.0990 - val_categorical_accuracy: 0.5226\n",
      "Epoch 385/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9095 - categorical_accuracy: 0.5147 - val_loss: 0.1013 - val_categorical_accuracy: 0.5194\n",
      "Epoch 386/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9255 - categorical_accuracy: 0.5112 - val_loss: 0.1014 - val_categorical_accuracy: 0.5204\n",
      "Epoch 387/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9325 - categorical_accuracy: 0.5125 - val_loss: 0.1002 - val_categorical_accuracy: 0.5114\n",
      "Epoch 388/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9199 - categorical_accuracy: 0.5081 - val_loss: 0.1025 - val_categorical_accuracy: 0.5186\n",
      "Epoch 389/500\n",
      "74491/74491 [==============================] - 2s 30us/sample - loss: 0.9366 - categorical_accuracy: 0.5097 - val_loss: 0.0993 - val_categorical_accuracy: 0.5222\n",
      "Epoch 390/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9123 - categorical_accuracy: 0.5134 - val_loss: 0.1029 - val_categorical_accuracy: 0.5028\n",
      "Epoch 391/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9428 - categorical_accuracy: 0.4986 - val_loss: 0.1037 - val_categorical_accuracy: 0.5088\n",
      "Epoch 392/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9515 - categorical_accuracy: 0.5000 - val_loss: 0.1028 - val_categorical_accuracy: 0.5236\n",
      "Epoch 393/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9393 - categorical_accuracy: 0.5130 - val_loss: 0.1015 - val_categorical_accuracy: 0.5100\n",
      "Epoch 394/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9295 - categorical_accuracy: 0.5046 - val_loss: 0.1041 - val_categorical_accuracy: 0.5140\n",
      "Epoch 395/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9572 - categorical_accuracy: 0.5083 - val_loss: 0.0996 - val_categorical_accuracy: 0.5218\n",
      "Epoch 396/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9127 - categorical_accuracy: 0.5130 - val_loss: 0.1050 - val_categorical_accuracy: 0.5096\n",
      "Epoch 397/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9577 - categorical_accuracy: 0.5021 - val_loss: 0.1004 - val_categorical_accuracy: 0.5198\n",
      "Epoch 398/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9222 - categorical_accuracy: 0.5128 - val_loss: 0.1020 - val_categorical_accuracy: 0.5164\n",
      "Epoch 399/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9389 - categorical_accuracy: 0.5092 - val_loss: 0.1020 - val_categorical_accuracy: 0.5070\n",
      "Epoch 400/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9352 - categorical_accuracy: 0.5033 - val_loss: 0.1005 - val_categorical_accuracy: 0.5188\n",
      "Epoch 401/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9206 - categorical_accuracy: 0.5123 - val_loss: 0.1020 - val_categorical_accuracy: 0.5172\n",
      "Epoch 402/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9333 - categorical_accuracy: 0.5099 - val_loss: 0.1010 - val_categorical_accuracy: 0.5128\n",
      "Epoch 403/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9236 - categorical_accuracy: 0.5068 - val_loss: 0.0997 - val_categorical_accuracy: 0.5196\n",
      "Epoch 404/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9151 - categorical_accuracy: 0.5117 - val_loss: 0.1002 - val_categorical_accuracy: 0.5206\n",
      "Epoch 405/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9210 - categorical_accuracy: 0.5140 - val_loss: 0.0997 - val_categorical_accuracy: 0.5240\n",
      "Epoch 406/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9151 - categorical_accuracy: 0.5138 - val_loss: 0.1000 - val_categorical_accuracy: 0.5170\n",
      "Epoch 407/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9171 - categorical_accuracy: 0.5107 - val_loss: 0.1000 - val_categorical_accuracy: 0.5232\n",
      "Epoch 408/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9184 - categorical_accuracy: 0.5144 - val_loss: 0.0993 - val_categorical_accuracy: 0.5212\n",
      "Epoch 409/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9122 - categorical_accuracy: 0.5133 - val_loss: 0.0996 - val_categorical_accuracy: 0.5210\n",
      "Epoch 410/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9147 - categorical_accuracy: 0.5117 - val_loss: 0.0998 - val_categorical_accuracy: 0.5234\n",
      "Epoch 411/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9152 - categorical_accuracy: 0.5143 - val_loss: 0.0989 - val_categorical_accuracy: 0.5248\n",
      "Epoch 412/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9090 - categorical_accuracy: 0.5154 - val_loss: 0.0997 - val_categorical_accuracy: 0.5142\n",
      "Epoch 413/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9156 - categorical_accuracy: 0.5092 - val_loss: 0.1000 - val_categorical_accuracy: 0.5236\n",
      "Epoch 414/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9179 - categorical_accuracy: 0.5128 - val_loss: 0.0987 - val_categorical_accuracy: 0.5240\n",
      "Epoch 415/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9074 - categorical_accuracy: 0.5150 - val_loss: 0.0988 - val_categorical_accuracy: 0.5242\n",
      "Epoch 416/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9090 - categorical_accuracy: 0.5130 - val_loss: 0.0995 - val_categorical_accuracy: 0.5222\n",
      "Epoch 417/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9139 - categorical_accuracy: 0.5142 - val_loss: 0.0999 - val_categorical_accuracy: 0.5236\n",
      "Epoch 418/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9165 - categorical_accuracy: 0.5121 - val_loss: 0.1002 - val_categorical_accuracy: 0.5206\n",
      "Epoch 419/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9225 - categorical_accuracy: 0.5138 - val_loss: 0.0992 - val_categorical_accuracy: 0.5192\n",
      "Epoch 420/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9111 - categorical_accuracy: 0.5116 - val_loss: 0.0999 - val_categorical_accuracy: 0.5224\n",
      "Epoch 421/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9142 - categorical_accuracy: 0.5132 - val_loss: 0.0995 - val_categorical_accuracy: 0.5246\n",
      "Epoch 422/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9140 - categorical_accuracy: 0.5145 - val_loss: 0.0999 - val_categorical_accuracy: 0.5132\n",
      "Epoch 423/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9160 - categorical_accuracy: 0.5083 - val_loss: 0.0997 - val_categorical_accuracy: 0.5212\n",
      "Epoch 424/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9142 - categorical_accuracy: 0.5133 - val_loss: 0.0991 - val_categorical_accuracy: 0.5261\n",
      "Epoch 425/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9091 - categorical_accuracy: 0.5157 - val_loss: 0.0992 - val_categorical_accuracy: 0.5210\n",
      "Epoch 426/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9110 - categorical_accuracy: 0.5124 - val_loss: 0.0991 - val_categorical_accuracy: 0.5251\n",
      "Epoch 427/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9087 - categorical_accuracy: 0.5146 - val_loss: 0.1012 - val_categorical_accuracy: 0.5198\n",
      "Epoch 428/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9250 - categorical_accuracy: 0.5115 - val_loss: 0.1021 - val_categorical_accuracy: 0.5164\n",
      "Epoch 429/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9406 - categorical_accuracy: 0.5112 - val_loss: 0.1006 - val_categorical_accuracy: 0.5168\n",
      "Epoch 430/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9242 - categorical_accuracy: 0.5092 - val_loss: 0.1008 - val_categorical_accuracy: 0.5204\n",
      "Epoch 431/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9226 - categorical_accuracy: 0.5137 - val_loss: 0.1000 - val_categorical_accuracy: 0.5218\n",
      "Epoch 432/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9148 - categorical_accuracy: 0.5130 - val_loss: 0.1013 - val_categorical_accuracy: 0.5114\n",
      "Epoch 433/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9276 - categorical_accuracy: 0.5075 - val_loss: 0.0997 - val_categorical_accuracy: 0.5267\n",
      "Epoch 434/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9146 - categorical_accuracy: 0.5143 - val_loss: 0.1003 - val_categorical_accuracy: 0.5250\n",
      "Epoch 435/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9176 - categorical_accuracy: 0.5159 - val_loss: 0.0990 - val_categorical_accuracy: 0.5255\n",
      "Epoch 436/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9093 - categorical_accuracy: 0.5153 - val_loss: 0.0994 - val_categorical_accuracy: 0.5222\n",
      "Epoch 437/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9137 - categorical_accuracy: 0.5144 - val_loss: 0.0989 - val_categorical_accuracy: 0.5204\n",
      "Epoch 438/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9057 - categorical_accuracy: 0.5126 - val_loss: 0.1002 - val_categorical_accuracy: 0.5194\n",
      "Epoch 439/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9156 - categorical_accuracy: 0.5123 - val_loss: 0.0995 - val_categorical_accuracy: 0.5202\n",
      "Epoch 440/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9143 - categorical_accuracy: 0.5132 - val_loss: 0.0995 - val_categorical_accuracy: 0.5206\n",
      "Epoch 441/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9144 - categorical_accuracy: 0.5125 - val_loss: 0.0994 - val_categorical_accuracy: 0.5250\n",
      "Epoch 442/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9123 - categorical_accuracy: 0.5158 - val_loss: 0.0988 - val_categorical_accuracy: 0.5248\n",
      "Epoch 443/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9054 - categorical_accuracy: 0.5157 - val_loss: 0.1001 - val_categorical_accuracy: 0.5122\n",
      "Epoch 444/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9175 - categorical_accuracy: 0.5073 - val_loss: 0.1019 - val_categorical_accuracy: 0.5164\n",
      "Epoch 445/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9348 - categorical_accuracy: 0.5104 - val_loss: 0.1029 - val_categorical_accuracy: 0.5086\n",
      "Epoch 446/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9430 - categorical_accuracy: 0.4946 - val_loss: 0.1037 - val_categorical_accuracy: 0.5038\n",
      "Epoch 447/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9533 - categorical_accuracy: 0.4947 - val_loss: 0.0992 - val_categorical_accuracy: 0.5228\n",
      "Epoch 448/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9118 - categorical_accuracy: 0.5139 - val_loss: 0.1041 - val_categorical_accuracy: 0.5028\n",
      "Epoch 449/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9532 - categorical_accuracy: 0.4961 - val_loss: 0.1050 - val_categorical_accuracy: 0.5086\n",
      "Epoch 450/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9640 - categorical_accuracy: 0.4974 - val_loss: 0.1001 - val_categorical_accuracy: 0.5206\n",
      "Epoch 451/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9181 - categorical_accuracy: 0.5132 - val_loss: 0.1039 - val_categorical_accuracy: 0.5114\n",
      "Epoch 452/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9504 - categorical_accuracy: 0.5028 - val_loss: 0.1009 - val_categorical_accuracy: 0.5230\n",
      "Epoch 453/500\n",
      "74491/74491 [==============================] - 2s 28us/sample - loss: 0.9251 - categorical_accuracy: 0.5135 - val_loss: 0.1022 - val_categorical_accuracy: 0.5158\n",
      "Epoch 454/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9380 - categorical_accuracy: 0.5067 - val_loss: 0.1002 - val_categorical_accuracy: 0.5218\n",
      "Epoch 455/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9196 - categorical_accuracy: 0.5124 - val_loss: 0.1024 - val_categorical_accuracy: 0.5078\n",
      "Epoch 456/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9374 - categorical_accuracy: 0.5022 - val_loss: 0.1008 - val_categorical_accuracy: 0.5184\n",
      "Epoch 457/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9246 - categorical_accuracy: 0.5101 - val_loss: 0.1002 - val_categorical_accuracy: 0.5186\n",
      "Epoch 458/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9220 - categorical_accuracy: 0.5106 - val_loss: 0.1012 - val_categorical_accuracy: 0.5176\n",
      "Epoch 459/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9304 - categorical_accuracy: 0.5086 - val_loss: 0.0992 - val_categorical_accuracy: 0.5222\n",
      "Epoch 460/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9126 - categorical_accuracy: 0.5125 - val_loss: 0.1004 - val_categorical_accuracy: 0.5194\n",
      "Epoch 461/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9219 - categorical_accuracy: 0.5106 - val_loss: 0.0992 - val_categorical_accuracy: 0.5202\n",
      "Epoch 462/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9104 - categorical_accuracy: 0.5123 - val_loss: 0.0986 - val_categorical_accuracy: 0.5224\n",
      "Epoch 463/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9079 - categorical_accuracy: 0.5144 - val_loss: 0.0989 - val_categorical_accuracy: 0.5251\n",
      "Epoch 464/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9102 - categorical_accuracy: 0.5154 - val_loss: 0.0995 - val_categorical_accuracy: 0.5293\n",
      "Epoch 465/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9146 - categorical_accuracy: 0.5155 - val_loss: 0.0986 - val_categorical_accuracy: 0.5232\n",
      "Epoch 466/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9095 - categorical_accuracy: 0.5151 - val_loss: 0.0981 - val_categorical_accuracy: 0.5236\n",
      "Epoch 467/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9026 - categorical_accuracy: 0.5149 - val_loss: 0.0995 - val_categorical_accuracy: 0.5253\n",
      "Epoch 468/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9115 - categorical_accuracy: 0.5146 - val_loss: 0.0993 - val_categorical_accuracy: 0.5244\n",
      "Epoch 469/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9137 - categorical_accuracy: 0.5147 - val_loss: 0.0988 - val_categorical_accuracy: 0.5208\n",
      "Epoch 470/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9075 - categorical_accuracy: 0.5122 - val_loss: 0.0989 - val_categorical_accuracy: 0.5271\n",
      "Epoch 471/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9063 - categorical_accuracy: 0.5157 - val_loss: 0.0987 - val_categorical_accuracy: 0.5259\n",
      "Epoch 472/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9062 - categorical_accuracy: 0.5158 - val_loss: 0.0985 - val_categorical_accuracy: 0.5230\n",
      "Epoch 473/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9047 - categorical_accuracy: 0.5136 - val_loss: 0.0981 - val_categorical_accuracy: 0.5257\n",
      "Epoch 474/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9004 - categorical_accuracy: 0.5159 - val_loss: 0.0983 - val_categorical_accuracy: 0.5283\n",
      "Epoch 475/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9025 - categorical_accuracy: 0.5168 - val_loss: 0.0983 - val_categorical_accuracy: 0.5273\n",
      "Epoch 476/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9030 - categorical_accuracy: 0.5145 - val_loss: 0.0980 - val_categorical_accuracy: 0.5267\n",
      "Epoch 477/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9015 - categorical_accuracy: 0.5169 - val_loss: 0.0983 - val_categorical_accuracy: 0.5261\n",
      "Epoch 478/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9009 - categorical_accuracy: 0.5164 - val_loss: 0.0980 - val_categorical_accuracy: 0.5248\n",
      "Epoch 479/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9000 - categorical_accuracy: 0.5158 - val_loss: 0.0978 - val_categorical_accuracy: 0.5261\n",
      "Epoch 480/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.8973 - categorical_accuracy: 0.5166 - val_loss: 0.0979 - val_categorical_accuracy: 0.5271\n",
      "Epoch 481/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.8982 - categorical_accuracy: 0.5171 - val_loss: 0.0976 - val_categorical_accuracy: 0.5259\n",
      "Epoch 482/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.8968 - categorical_accuracy: 0.5168 - val_loss: 0.0976 - val_categorical_accuracy: 0.5261\n",
      "Epoch 483/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.8959 - categorical_accuracy: 0.5166 - val_loss: 0.0980 - val_categorical_accuracy: 0.5271\n",
      "Epoch 484/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.8986 - categorical_accuracy: 0.5171 - val_loss: 0.0983 - val_categorical_accuracy: 0.5226\n",
      "Epoch 485/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9022 - categorical_accuracy: 0.5143 - val_loss: 0.1001 - val_categorical_accuracy: 0.5238\n",
      "Epoch 486/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9204 - categorical_accuracy: 0.5138 - val_loss: 0.1029 - val_categorical_accuracy: 0.5190\n",
      "Epoch 487/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9415 - categorical_accuracy: 0.5055 - val_loss: 0.1033 - val_categorical_accuracy: 0.5140\n",
      "Epoch 488/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9516 - categorical_accuracy: 0.5069 - val_loss: 0.0993 - val_categorical_accuracy: 0.5202\n",
      "Epoch 489/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9125 - categorical_accuracy: 0.5124 - val_loss: 0.1015 - val_categorical_accuracy: 0.5150\n",
      "Epoch 490/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9266 - categorical_accuracy: 0.5064 - val_loss: 0.1017 - val_categorical_accuracy: 0.5144\n",
      "Epoch 491/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9308 - categorical_accuracy: 0.5045 - val_loss: 0.0999 - val_categorical_accuracy: 0.5182\n",
      "Epoch 492/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9184 - categorical_accuracy: 0.5082 - val_loss: 0.1007 - val_categorical_accuracy: 0.5122\n",
      "Epoch 493/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9251 - categorical_accuracy: 0.5057 - val_loss: 0.1011 - val_categorical_accuracy: 0.5146\n",
      "Epoch 494/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9281 - categorical_accuracy: 0.5077 - val_loss: 0.1001 - val_categorical_accuracy: 0.5202\n",
      "Epoch 495/500\n",
      "74491/74491 [==============================] - 2s 25us/sample - loss: 0.9179 - categorical_accuracy: 0.5121 - val_loss: 0.1015 - val_categorical_accuracy: 0.5074\n",
      "Epoch 496/500\n",
      "74491/74491 [==============================] - 2s 27us/sample - loss: 0.9300 - categorical_accuracy: 0.5019 - val_loss: 0.0996 - val_categorical_accuracy: 0.5234\n",
      "Epoch 497/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9133 - categorical_accuracy: 0.5138 - val_loss: 0.0996 - val_categorical_accuracy: 0.5238\n",
      "Epoch 498/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9132 - categorical_accuracy: 0.5143 - val_loss: 0.0992 - val_categorical_accuracy: 0.5232\n",
      "Epoch 499/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9110 - categorical_accuracy: 0.5128 - val_loss: 0.0987 - val_categorical_accuracy: 0.5246\n",
      "Epoch 500/500\n",
      "74491/74491 [==============================] - 2s 26us/sample - loss: 0.9081 - categorical_accuracy: 0.5152 - val_loss: 0.0986 - val_categorical_accuracy: 0.5253\n"
     ]
    }
   ],
   "source": [
    "# Define validation data\n",
    "validation_data = ([X, fltr], Y, val_mask)\n",
    "\n",
    "history = model.fit([X, fltr],\n",
    "          Y,\n",
    "          sample_weight=train_mask,\n",
    "          epochs=epochs,\n",
    "          batch_size=N,\n",
    "          validation_data=validation_data,\n",
    "          shuffle=False,  # Shuffling data means shuffling the whole graph\n",
    "          callbacks=[\n",
    "              EarlyStopping(patience=50,  restore_best_weights=True)\n",
    "          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(history.history['loss'], label='loss')\n",
    "ax.plot(history.history['val_loss'], label='val_loss')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(history.history['categorical_accuracy'], label='categorical_accuracy')\n",
    "ax.plot(history.history['val_categorical_accuracy'], label='val_categorical_accuracy')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(modelfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
